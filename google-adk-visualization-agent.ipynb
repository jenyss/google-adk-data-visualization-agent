{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5986b0d3-02e2-443b-8d12-b3b951e75dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install google-adk\n",
    "%pip install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae55017-599c-4c7c-a907-7c658ba4b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas python-dotenv duckdb numpy plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4794f53-a0aa-4dca-aee0-fb5a8ade0f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key_openai=os.getenv(\"OPENAI_API_KEY\")\n",
    "api_key_google=os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if api_key_openai and api_key_google:\n",
    "    print(\"Keys loaded\")\n",
    "else:\n",
    "    print(\"Keys are not loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eaeb196-1a4a-46ea-a9aa-7a3afa35d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"False\"\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY\"  # Replace with your actual key here OR add it to your .env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9daf4d0c-df89-430b-8547-0c107a7ec5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.adk.agents import Agent\n",
    "from google.genai.types import GenerationConfig\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.genai.types import Content, Part\n",
    "from google.adk.tools import google_search\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.adk.models.lite_llm import LiteLlm # For multi-model support\n",
    "import asyncio\n",
    "\n",
    "# from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fee0551-f0d9-472e-ad09-33e6f584de3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import duckdb\n",
    "from typing import TypedDict, Optional, List, Dict, Union, Any\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad20fcf7-80c6-421b-a84e-410403ce43d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Robust preprocessing of DataFrame to handle empty values.\"\"\"\n",
    "    # Convert empty strings and whitespace to None\n",
    "    df = df.replace(r'^\\s*$', None, regex=True)\n",
    "    # Convert NaN strings to None\n",
    "    df = df.replace(['nan', 'NaN', 'null'], None)\n",
    "    # Convert pandas NaN to None\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    return df\n",
    "\n",
    "\n",
    "def preview_excel_structure(input_str: str, tool_context: ToolContext) -> str:\n",
    "    \"\"\"\n",
    "    Use this first to examine the Excel file structure and data types. \n",
    "    The input should be a JSON string with format: {\"file_name\": \"your_file.xlsx\"}\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = json.loads(input_str)\n",
    "        file_name = data.get(\"file_name\")\n",
    "        if not file_name:\n",
    "            return json.dumps({\"error\": \"File name must be provided\"})\n",
    "\n",
    "        df = pd.read_excel(file_name)\n",
    "        df = preprocess_dataframe(df)  # Apply preprocessing\n",
    "        df_sample = df.head(3).astype(str)\n",
    "\n",
    "        print(\"‚úÖ Preview successful\")\n",
    "        display(df_sample)\n",
    "\n",
    "        result = {\n",
    "            \"columns\": df.columns.tolist(),\n",
    "            \"dtypes\": df.dtypes.astype(str).to_dict(),\n",
    "            \"sample_rows\": df_sample.to_dict(orient=\"records\")\n",
    "        }\n",
    "\n",
    "        # Persist result to state\n",
    "        tool_context.state[\"preview_structure\"] = result\n",
    "        tool_context.state[\"file_name\"] = file_name  # also store file name for later tools\n",
    "        tool_context.state[\"full_data_rows\"] = df.to_dict(orient=\"records\")\n",
    "\n",
    "\n",
    "        # print(\"üîç Tool Context State:\\n\", tool_context.state.to_dict())\n",
    "\n",
    "        return json.dumps({ \"result\": result })\n",
    "\n",
    "    except Exception as e:\n",
    "        return json.dumps({ \"error\": str(e) })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f67b58f4-0a07-41db-bef2-76692689ba1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_duckdb_query(input_data: dict, tool_context: ToolContext) -> str:\n",
    "    \"\"\"\n",
    "    Use this tool for SQL operations (GROUP BY, aggregations, etc.).\n",
    "\n",
    "    Args:\n",
    "        input_data (dict): A dictionary with the following keys:\n",
    "            - \"file_name\" (str): Name of the Excel file to query (optional if already stored in state).\n",
    "            - \"query\" (str): SQL query to run against the file.\n",
    "\n",
    "    Returns:\n",
    "        str: JSON string with structure:\n",
    "            {\n",
    "                \"status\": \"success\",\n",
    "                \"message\": \"...\",\n",
    "                \"result\": {\n",
    "                    \"columns\": [...],\n",
    "                    \"rows\": [...]\n",
    "                }\n",
    "            }\n",
    "            or an error message.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Validate input\n",
    "        if not isinstance(input_data, dict):\n",
    "            return json.dumps({\"error\": \"Input must be a dictionary.\"})\n",
    "\n",
    "        query = input_data.get(\"query\")\n",
    "        \n",
    "        file_name = input_data.get(\"file_name\") or tool_context.state.get(\"file_name\")\n",
    "\n",
    "        if not file_name:\n",
    "            return json.dumps({\"error\": \"'file_name' must be provided or available in state.\"})\n",
    "\n",
    "        if not isinstance(query, str) or not query.strip():\n",
    "            return json.dumps({\"error\": \"'query' must be a non-empty string.\"})\n",
    "\n",
    "        print(\"\\nüîç Executing DuckDB query:\")\n",
    "        print(query)\n",
    "        print(file_name)\n",
    "\n",
    "        # df = pd.read_excel(file_name)\n",
    "        df = pd.DataFrame(tool_context.state[\"full_data_rows\"])\n",
    "\n",
    "        df = preprocess_dataframe(df)\n",
    "\n",
    "        with duckdb.connect() as con:\n",
    "            con.register(\"data\", df)\n",
    "            query = query.replace(file_name, \"data\")\n",
    "            result = con.execute(query).fetchdf()\n",
    "            print(\"‚úÖ Query successful\")\n",
    "            display(result)\n",
    "\n",
    "            if isinstance(result, pd.DataFrame):\n",
    "                df_processed = result.copy()\n",
    "                df_processed = df_processed.replace([float('inf'), -float('inf')], None)\n",
    "                df_processed = df_processed.where(pd.notna(df_processed), None)\n",
    "\n",
    "                for column in df_processed.columns:\n",
    "                    if df_processed[column].dtype == 'object':\n",
    "                        df_processed[column] = df_processed[column].apply(\n",
    "                            lambda x: str(x) if x is not None else None\n",
    "                        )\n",
    "\n",
    "                result_dict = {\n",
    "                    \"columns\": df_processed.columns.tolist(),\n",
    "                    \"rows\": df_processed.to_dict(orient=\"records\")\n",
    "                }\n",
    "\n",
    "                # Store in state\n",
    "                tool_context.state[\"last_query\"] = query\n",
    "                tool_context.state[\"query_result\"] = result_dict\n",
    "\n",
    "                # print(\"üîç Tool Context State:\\n\", tool_context.state.to_dict())\n",
    "\n",
    "                return json.dumps({\n",
    "                    \"status\": \"success\",\n",
    "                    \"message\": \"Query executed successfully. You can now proceed to create the visualization.\",\n",
    "                    \"result\": result_dict\n",
    "                })\n",
    "\n",
    "            else:\n",
    "                tool_context.state[\"last_query\"] = query\n",
    "                tool_context.state[\"query_result\"] = str(result)\n",
    "                return json.dumps({\"status\": \"success\", \"result\": str(result)})\n",
    "\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50a9fb00-3d3b-45e2-9b7b-1683ddf243dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_visualization(input_data: dict, tool_context: ToolContext) -> str:\n",
    "    \"\"\"\n",
    "    Create and immediately display various types of visualizations using Plotly.\n",
    "    \n",
    "    Args:\n",
    "        input_data (dict): A dictionary with the following keys:\n",
    "            {\n",
    "              \"data\": {\n",
    "                \"result\": {\n",
    "                  \"rows\": [...],\n",
    "                  \"columns\": [...]\n",
    "                }\n",
    "              },\n",
    "              \"plot_type\": \"...\",\n",
    "              \"x\": \"...\",\n",
    "              \"y\": \"...\",\n",
    "              \"title\": \"...\",\n",
    "              \"color\": \"...\",\n",
    "              \"source\": \"...\",    # For Sankey\n",
    "              \"target\": \"...\",    # For Sankey\n",
    "              \"value\": \"...\"      # For Sankey\n",
    "            }\n",
    "        tool_context (ToolContext): Injected by ADK to access session state.\n",
    "\n",
    "    Returns:\n",
    "        str: A success message or an error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(\"üìä create_visualization tool was called.\")\n",
    "        \n",
    "        # Fallback from context\n",
    "        if input_data is None and tool_context:\n",
    "            input_data = tool_context.state.get(\"query_result\")\n",
    "            print(\"üì• Used query_result from session state.\")\n",
    "\n",
    "        if not input_data:\n",
    "            return \"‚ùå Error: No input data provided for visualization.\"\n",
    "\n",
    "        print(\"üìä Input received for visualization:\", json.dumps(input_data, indent=2))\n",
    "        \n",
    "        params = input_data\n",
    "        data = params.get(\"data\")\n",
    "        plot_type = params.get(\"plot_type\", \"line\")\n",
    "        x = params.get(\"x\")\n",
    "        y = params.get(\"y\")\n",
    "        title = params.get(\"title\", \"\")\n",
    "        color = params.get(\"color\")\n",
    "        orientation = params.get(\"orientation\", \"v\")\n",
    "        barmode = params.get(\"barmode\", \"group\")\n",
    "        size = params.get(\"size\")\n",
    "        nbins = params.get(\"nbins\")\n",
    "        source = params.get(\"source\")\n",
    "        target = params.get(\"target\")\n",
    "        value = params.get(\"value\")\n",
    "\n",
    "        # Validate and convert\n",
    "        if not data or not x:\n",
    "            return \"‚ùå Error: Missing required parameters: data and x.\"\n",
    "        \n",
    "        if isinstance(data, dict) and \"result\" in data and \"rows\" in data[\"result\"]:\n",
    "            df = pd.DataFrame(data[\"result\"][\"rows\"])\n",
    "        else:\n",
    "            return \"‚ùå Error: Invalid data format.\"\n",
    "\n",
    "        # Layout\n",
    "        layout_settings = {\n",
    "            'title': {'text': title, 'x': 0.5, 'xanchor': 'center', 'font': dict(size=16)},\n",
    "            'plot_bgcolor': 'white',\n",
    "            'paper_bgcolor': 'white',\n",
    "            'font': dict(size=12),\n",
    "            'margin': dict(l=50, r=50, t=50, b=100),\n",
    "            'height': 800,\n",
    "            'width': 1600,\n",
    "            'template': 'plotly_white'\n",
    "        }\n",
    "\n",
    "        if plot_type == \"line\":\n",
    "            fig = px.line(df, x=x, y=y, color=color, title=title)\n",
    "            fig.update_traces(mode='lines+markers')\n",
    "        elif plot_type == \"bar\":\n",
    "            fig = px.bar(df, x=x, y=y, color=color, title=title, barmode=barmode, orientation=orientation)\n",
    "        elif plot_type == \"scatter\":\n",
    "            fig = px.scatter(df, x=x, y=y, color=color, size=size, title=title)\n",
    "        elif plot_type == \"box\":\n",
    "            fig = px.box(df, x=x, y=y, color=color, title=title)\n",
    "        elif plot_type == \"histogram\":\n",
    "            fig = px.histogram(df, x=x, color=color, nbins=nbins, title=title)\n",
    "        elif plot_type == \"pie\":\n",
    "            fig = px.pie(df, names=x, values=y if y else None, color=x, title=title)\n",
    "        elif plot_type == \"heatmap\":\n",
    "            if len(df.columns) < 3:\n",
    "                pivot_df = df.pivot(index=y, columns=x, values=color if color else 'value')\n",
    "                fig = px.imshow(pivot_df, title=title)\n",
    "            else:\n",
    "                fig = px.imshow(df, title=title)\n",
    "        elif plot_type == \"sankey\":\n",
    "            if not (source and target and value):\n",
    "                return \"‚ùå Error: Sankey diagrams require 'source', 'target', and 'value'.\"\n",
    "            \n",
    "            # Sankey: compute unique node labels and indices\n",
    "            unique_nodes = list(dict.fromkeys(df[source].tolist() + df[target].tolist()))\n",
    "            source_indices = df[source].apply(lambda x: unique_nodes.index(x))\n",
    "            target_indices = df[target].apply(lambda x: unique_nodes.index(x))\n",
    "\n",
    "            # Add total flow per node\n",
    "            label_with_values = []\n",
    "            for node in unique_nodes:\n",
    "                total_val = df[df[source] == node][value].sum() + df[df[target] == node][value].sum()\n",
    "                label_with_values.append(f\"{node}\\n({total_val:,.2f})\")\n",
    "\n",
    "            fig = go.Figure(data=[go.Sankey(\n",
    "                arrangement=\"freeform\",\n",
    "                domain=dict(x=[0, 1], y=[0.1, 0.90]),\n",
    "                node=dict(\n",
    "                    pad=70, thickness=30,\n",
    "                    line=dict(color=\"black\", width=0.9),\n",
    "                    label=label_with_values\n",
    "                ),\n",
    "                link=dict(\n",
    "                    source=source_indices,\n",
    "                    target=target_indices,\n",
    "                    value=df[value]\n",
    "                )\n",
    "            )])\n",
    "            fig.update_layout(\n",
    "                title_text=title,\n",
    "                font=dict(size=16, family=\"Arial, sans-serif\", color=\"black\"),\n",
    "                plot_bgcolor='white',\n",
    "                paper_bgcolor='white',\n",
    "                margin=dict(l=50, r=50, t=50, b=50)\n",
    "            )\n",
    "        else:\n",
    "            return f\"‚ùå Error: Unsupported plot type: {plot_type}.\"\n",
    "\n",
    "        fig.update_layout(layout_settings)\n",
    "\n",
    "        if plot_type not in ['pie', 'heatmap']:\n",
    "            fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='LightGray', title_text=x.replace('_', ' ').title())\n",
    "            if y:\n",
    "                fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGray', title_text=y.replace('_', ' ').title())\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "        if tool_context:\n",
    "            tool_context.state[\"last_visualization\"] = {\n",
    "                \"plot_type\": plot_type,\n",
    "                \"x\": x, \"y\": y, \"title\": title, \"color\": color\n",
    "            }\n",
    "\n",
    "        # print(\"üîç Tool Context State:\\n\", tool_context.state.to_dict())\n",
    "\n",
    "        return \"‚úÖ Visualization displayed successfully.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Visualization error: {str(e)}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "849783df-5dc8-4b03-b627-b99415980f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = LiteLlm(\n",
    "    model=\"openai/gpt-4o\",\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "root_agent = Agent(\n",
    "    name=\"data_agent\",\n",
    "    model=llm,\n",
    "    # model=\"gemini-2.0-flash-exp\", #gemini-2.0-flash-exp, gemini-2.5-pro-preview-03-25 gemini-2.5-pro-exp-03-25\n",
    "    description=(\n",
    "        \"Agent to answer data questions and create visualizations.\"\n",
    "    ),\n",
    "    instruction=(\n",
    "        \"\"\"\n",
    "You will be given a task to perform. You must follow these exact steps in order:\n",
    "\n",
    "1. Always call the `preview_excel_structure` tool first to get the Excel columns. Match user input terms to Excel column names. You MUST print the matched values before continuing.\n",
    "2. Use the matched column names to build SQL query using the `complex_duckdb_query` tool. \n",
    "\n",
    "**IMPORTANT:** \n",
    "   - The table is registered as `data`. \n",
    "   - DO NOT use the file name or sheet name. \n",
    "   - Always query using `FROM data`.\n",
    "\n",
    "   \n",
    "3. Use the results of the SQL query to generate a Plotly visualization using the `create_visualization` tool. \n",
    "   - If user asks for a specific chart type (e.g., Sankey), use that.\n",
    "   - ALWAYS convert wide-format data (e.g., a single row of many metrics) into long-format JSON before calling create_visualization.\n",
    "\n",
    "**Visualization Output Format (CRITICAL):**\n",
    "\n",
    "{\n",
    "  \"data\": { \"result\": { \"columns\": [...], \"rows\": [...] } },\n",
    "  \"plot_type\": \"...\",\n",
    "  \"x\": \"column_name_for_x_axis\",\n",
    "  \"y\": \"column_name_for_y_axis\",\n",
    "  \"title\": \"...\",\n",
    "  \"color\": \"...\",\n",
    "}\n",
    "\n",
    "\n",
    "**Sankey example:**\n",
    " {\n",
    "  \"data\": {\n",
    "    \"result\": {\n",
    "      \"rows\": [\n",
    "        { \"source\": \"Company\", \"target\": \"Contacted by recruiter\", \"value\": 1 },\n",
    "        { \"source\": \"Contacted by recruiter\", \"target\": \"Recruiter interview\", \"value\": 16 },\n",
    "        { \"source\": \"Recruiter interview\", \"target\": \"1st round\", \"value\": 7 },\n",
    "        { \"source\": \"1st round\", \"target\": \"Challenge / Assignment\", \"value\": 4 },\n",
    "        { \"source\": \"Challenge / Assignment\", \"target\": \"2nd round\", \"value\": 4 },\n",
    "        { \"source\": \"2nd round\", \"target\": \"3rd round\", \"value\": 1 },\n",
    "        { \"source\": \"3rd round\", \"target\": \"Opening closed / put on hold\", \"value\": 1 },\n",
    "        { \"source\": null, \"target\": \"1st round\", \"value\": 6 },\n",
    "      ],\n",
    "      \"columns\": [\"source\", \"target\", \"value\"]\n",
    "    }\n",
    "  },\n",
    "  \"plot_type\": \"sankey\",\n",
    "  \"title\": \"Job Application Process Transitions\",\n",
    "  \"x\": \"source\",\n",
    "  \"source\": \"source\",\n",
    "  \"target\": \"target\",\n",
    "  \"value\": \"value\"\n",
    "}\n",
    "   \n",
    "4. Display the visualization.\n",
    "5. Evaluate if the task is completed. If the visualization was shown successfully OR if task completed, stop execution!\n",
    "\n",
    "        \"\"\"\n",
    "    ),\n",
    "    tools=[preview_excel_structure, complex_duckdb_query, create_visualization],\n",
    "    output_key=\"last_agent_response\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9f0815-0644-47cf-b8b4-d82307dfaef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the session and runner\n",
    "session_service = InMemorySessionService()\n",
    "app_name = \"viz_app\"\n",
    "user_id = \"jeny\"\n",
    "session_id = \"session_viz_001\"\n",
    "session = session_service.create_session(app_name=app_name, user_id=user_id, session_id=session_id)\n",
    "\n",
    "# session = session_service.create_session(app_name=app_name, user_id=user_id)\n",
    "\n",
    "runner = Runner(agent=root_agent, app_name=app_name, session_service=session_service)\n",
    "\n",
    "# Create the user message\n",
    "user_message = Content(role=\"user\", parts=[Part(text=\"\"\"\n",
    "Use file: data_export.xlsx to\n",
    "    1. Create and display a visualization which shows how the total Forcast flows through the unique groups in Channel and subchannel`\n",
    "    2. You must follow this sankey flow: Source (Total forecast) -> target (Channel); Source (Channel) -> target (sub-channel)\n",
    "    3. Visualization name: Total Forecast flow through Channel, Sub Channel\n",
    "\n",
    "\"\"\")])\n",
    "\n",
    "# Run and display the final response\n",
    "for event in runner.run(user_id=user_id, session_id=session.id, new_message=user_message):\n",
    "    if event.is_final_response():\n",
    "        if event.content and event.content.parts:\n",
    "            print(event.content.parts[0].text)\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è No final text response was returned by the agent.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f13315d-3de1-4c0c-a35d-fd904bd2adcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
